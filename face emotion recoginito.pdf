# ==========================================
# High Accuracy Face Emotion Recognition
# ==========================================

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import cv2
import time
import numpy as np
import mediapipe as mp
from collections import deque
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array

# ------------------------------------------
# Load Emotion Model
# ------------------------------------------
emotion_model_path = "models/_mini_XCEPTION.102-0.66.hdf5"
emotion_classifier = load_model(emotion_model_path, compile=False)

EMOTIONS = ["angry", "disgust", "scared",
            "happy", "sad", "surprised", "neutral"]

# ------------------------------------------
# MediaPipe Face Detector (High Accuracy)
# ------------------------------------------
mp_face = mp.solutions.face_detection
face_detection = mp_face.FaceDetection(
    model_selection=0, min_detection_confidence=0.7
)

# ------------------------------------------
# Emotion Smoothing (reduces flicker)
# ------------------------------------------
emotion_queue = deque(maxlen=10)

# ------------------------------------------
# Start Webcam
# ------------------------------------------
camera = cv2.VideoCapture(0)
time.sleep(2)

print("[INFO] Press 'Q' to quit")

# ------------------------------------------
# Main Loop
# ------------------------------------------
while True:
    ret, frame = camera.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    results = face_detection.process(rgb_frame)

    canvas = np.zeros((250, 350, 3), dtype="uint8")

    if results.detections:
        detection = results.detections[0]
        box = detection.location_data.relative_bounding_box

        x = int(box.xmin * w)
        y = int(box.ymin * h)
        bw = int(box.width * w)
        bh = int(box.height * h)

        x, y = max(0, x), max(0, y)

        face = frame[y:y+bh, x:x+bw]
        if face.size != 0:
            gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
            gray = cv2.equalizeHist(gray)
            gray = cv2.resize(gray, (64, 64))
            gray = gray.astype("float32") / 255.0

            roi = img_to_array(gray)
            roi = np.expand_dims(roi, axis=0)

            preds = emotion_classifier.predict(roi, verbose=0)[0]

            emotion_queue.append(preds)
            avg_preds = np.mean(emotion_queue, axis=0)

            label = EMOTIONS[np.argmax(avg_preds)]

            # Draw face box
            cv2.rectangle(frame, (x, y), (x + bw, y + bh),
                          (0, 255, 0), 2)
            cv2.putText(frame, label, (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                        (0, 255, 0), 2)

            # Probability bars
            for i, (emotion, prob) in enumerate(zip(EMOTIONS, avg_preds)):
                text = f"{emotion}: {prob * 100:.2f}%"
                bar_width = int(prob * 300)

                cv2.rectangle(canvas,
                              (10, i * 30 + 5),
                              (10 + bar_width, i * 30 + 30),
                              (0, 255, 0), -1)

                cv2.putText(canvas, text,
                            (15, i * 30 + 25),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.45, (255, 255, 255), 1)

    # ------------------------------------------
    # Display
    # ------------------------------------------
    cv2.imshow("Emotion Recognition (High Accuracy)", frame)
    cv2.imshow("Emotion Probabilities", canvas)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ------------------------------------------
# Cleanup
# ------------------------------------------
camera.release()
cv2.destroyAllWindows()
